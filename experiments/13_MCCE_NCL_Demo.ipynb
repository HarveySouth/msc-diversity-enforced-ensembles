{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "This notebook runs the negative correlation algorithm for squared loss through pytorch, and measure the diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # local\n",
    "project_directory = \"../\"\n",
    "\n",
    "\n",
    "# # # # colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# project_directory = \"/content/drive/MyDrive/colab_working_directory/diversity-enforced-ensembles/\"\n",
    "# !pip install cached-property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "# allow import of decompose locally\n",
    "import sys\n",
    "sys.path.append(project_directory + 'src/')\n",
    "\n",
    "from decompose import CrossEntropy\n",
    "import bvdlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import ml_utils\n",
    "from ml_utils.torch_data_utils import minimal_implementation_dataset\n",
    "from ml_utils.ensemble_utils import ImageWOOF_SimpleConvnet\n",
    "from ml_utils.ensemble_utils import Ensemble_Runner\n",
    "from ml_utils.ensemble_utils import torch_MCCE_logit_combiner\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from fastai.data.external import untar_data\n",
    "from fastai.data.external import URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# mock_member_logit_output = torch.rand((11, 3, 10))\n",
    "# ens_logit_output = torch.mean(mock_member_logit_output, dim=0)\n",
    "# member_prob_output = torch.functional.F.softmax(mock_member_logit_output, dim=-1)\n",
    "\n",
    "# target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "\n",
    "\n",
    "# ens_norm_mean = norm_geo_mean(member_prob_output)\n",
    "# ens_soft_out = torch.functional.F.softmax(ens_logit_output, dim=-1)\n",
    "\n",
    "# print(nn.CrossEntropyLoss()(ens_logit_output, target))\n",
    "# print(nn.NLLLoss()(torch.log(ens_norm_mean), target))\n",
    "\n",
    "# diff = ens_soft_out - ens_norm_mean #allclose is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mock_member_logit_output = torch.rand((11, 3, 10))\n",
    "# ens_logit_output = torch.mean(mock_member_logit_output, dim=0)\n",
    "# member_prob_output = torch.functional.F.softmax(mock_member_logit_output, dim=-1)\n",
    "\n",
    "# target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "\n",
    "\n",
    "# ens_norm_mean = norm_geo_mean(member_prob_output)\n",
    "# ens_soft_out = torch.functional.F.softmax(ens_logit_output, dim=-1)\n",
    "\n",
    "# print(nn.CrossEntropyLoss()(ens_logit_output, target))\n",
    "# print(nn.NLLLoss()(torch.log(ens_norm_mean), target))\n",
    "\n",
    "# diff = ens_soft_out - ens_norm_mean #allclose is 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_without_extension = project_directory + \"experiments/results/MCCE_NCL_ImageWOOF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "\n",
    "data_path = untar_data(URLs.IMAGEWOOF_160)\n",
    "\n",
    "\n",
    "smallest_training_resolution = 160 # its a square\n",
    "imagenet_transform_mean = np.mean([0.485, 0.456, 0.406])\n",
    "imagenet_transform_std = np.mean([0.229, 0.224, 0.225])\n",
    "\n",
    "transformation = transforms.Compose([\n",
    "    \n",
    "    transforms.ToPILImage(),\n",
    "    transforms.CenterCrop(smallest_training_resolution),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_transform_mean,std=imagenet_transform_std),\n",
    "    \n",
    "])  \n",
    "\n",
    "\n",
    "training_data = datasets.DatasetFolder(\n",
    "    root = data_path / 'train',\n",
    "    loader = lambda x: torchvision.io.read_image(x),\n",
    "    extensions = ('.jpg', '.jpeg', '.png'),\n",
    "    transform = transformation\n",
    ")\n",
    "\n",
    "testing_data = datasets.DatasetFolder(\n",
    "    root = data_path / 'val',\n",
    "    loader = lambda x: torchvision.io.read_image(x),\n",
    "    extensions = ('.jpg', '.jpeg', '.png'),\n",
    "    transform = transformation\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i, img in enumerate(training_data):\n",
    "    x, y = img\n",
    "    train_data.append(x)\n",
    "train_data = np.expand_dims(np.array(train_data).squeeze(), axis=1) # sorry!\n",
    "train_labels = np.array(training_data.targets)\n",
    "\n",
    "test_data = []\n",
    "for i, img in enumerate(testing_data):\n",
    "    x, y = img\n",
    "    test_data.append(x)\n",
    "test_data = np.expand_dims(np.array(test_data).squeeze(), axis=1)# sorry!\n",
    "test_labels = np.array(testing_data.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shapes (9025, 1, 160, 160) (9025,)\n",
      "Testing shapes (3929, 1, 160, 160) (3929,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training shapes\", train_data.shape, train_labels.shape)\n",
    "print(\"Testing shapes\", test_data.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # used in getting minimum training data resolutons\n",
    "# min1=200\n",
    "# min2=200\n",
    "# for i, (dat, y) in enumerate(training_data):\n",
    "#     imgs = dat.size()\n",
    "#     res1=imgs[1]\n",
    "#     res2=imgs[2]\n",
    "#     if res1 < min1:\n",
    "#         min1=res1\n",
    "#     if res2 < min2:\n",
    "#         min2=res2 \n",
    "# print(min1, min2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_fn = CrossEntropy\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "test_dset = minimal_implementation_dataset(test_data, test_labels, device)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size = len(test_dset) // 30, shuffle=False)\n",
    "chosen_model = ImageWOOF_SimpleConvnet\n",
    "combiner_rule = torch_MCCE_logit_combiner\n",
    "\n",
    "parameter_dictionary = {\n",
    "    \"epoch_n\": 4,\n",
    "    \"estimator_n\": 5,\n",
    "    \"batch_size\" : 128,\n",
    "    # \"hidden_size\" : 24,\n",
    "    # \"hidden_layer_num\" : 2,\n",
    "    \"device\" : device,\n",
    "    \"combiner_rule\" : combiner_rule,\n",
    "    \"criterion\" : criterion,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 7\n",
    "data_percentage_training = len(train_labels)\n",
    "num_training =  int(0.8 * data_percentage_training) # percent of data for each trial from training\n",
    "trial_space = np.arange(0,7, 0.5) / 10\n",
    "experiment_seed = 0\n",
    "torch_generator = torch.manual_seed(experiment_seed)\n",
    "\n",
    "consider_epoch_every_x_steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagewoof_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.func import stack_module_state\n",
    "from torch import vmap\n",
    "from torch.func import functional_call\n",
    "import copy\n",
    "\n",
    "class Ensemble_Runner():\n",
    "    def __init__(self, exmaple_model, combiner_rule):\n",
    "        self.metamodel = copy.deepcopy(exmaple_model).to('meta')\n",
    "        self.combiner_rule = combiner_rule\n",
    "        \n",
    "    def forward_through_metamodel(self, params, buffers, x):\n",
    "        return functional_call(self.metamodel, (params, buffers), (x,))\n",
    "    \n",
    "    def forward(self, x, ensemble):\n",
    "        params, buffers = stack_module_state(nn.ModuleList(ensemble))\n",
    "        \n",
    "        # print(x.shape)\n",
    "\n",
    "        # print(x.repeat(len(ensemble), 1, 1, 1, 1).shape)\n",
    "\n",
    "        member_output = vmap(self.forward_through_metamodel)(params, buffers, x.repeat(len(ensemble), 1, 1, 1, 1))\n",
    "\n",
    "        # print(member_output.shape)\n",
    "\n",
    "        ensemble_output = self.combiner_rule(member_output)\n",
    "\n",
    "        # print(ensemble_output.shape)\n",
    "        return ensemble_output, member_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3035, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3035, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3035, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3035, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3035, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3582, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3582, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3582, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3582, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3582, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3005, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3005, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3005, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3005, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3005, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2976, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2976, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2976, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2976, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2976, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3044, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3044, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3044, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3044, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3044, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3001, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3001, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3001, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3001, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3001, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3120, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3120, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3120, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3120, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3120, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2956, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2956, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2956, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2956, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2956, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2972, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2972, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2972, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2972, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2972, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2891, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2891, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2891, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2891, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2891, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3102, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3102, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3102, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3102, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3102, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2887, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2887, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2887, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2887, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2887, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2955, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2955, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2955, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2955, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2955, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2641, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2641, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2641, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2641, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2641, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3083, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3083, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3083, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3083, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3083, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2937, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2937, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2937, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2937, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2937, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2937, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2937, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2937, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2937, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2937, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2704, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2704, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2704, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2704, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2704, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2996, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2996, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2996, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2996, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2996, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2649, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2649, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2649, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2649, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2649, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2430, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2430, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2430, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2430, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2430, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3087, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3087, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3087, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3087, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3087, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2730, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2730, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2730, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2730, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2730, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2733, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2733, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2733, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2733, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2733, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2662, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2662, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2662, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2662, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2662, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2985, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2985, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2985, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2985, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2985, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2485, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2485, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2485, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2485, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2485, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2475, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2475, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2475, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2475, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2475, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2811, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2811, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2811, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2811, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2811, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2585, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2585, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2585, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2585, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2585, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2576, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2576, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2576, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2576, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2576, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2672, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2672, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2672, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2672, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2672, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2879, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2879, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2879, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2879, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2879, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2644, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2644, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2644, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2644, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2644, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2345, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2345, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2345, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2345, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2345, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3004, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3004, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3004, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3004, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3004, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2776, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2776, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2776, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2776, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2776, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2528, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2528, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2528, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2528, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2528, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2435, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2435, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2435, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2435, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2435, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2569, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2569, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2569, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2569, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2569, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2921, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2921, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2921, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2921, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2921, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2978, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2978, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2978, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2978, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2978, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2483, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2483, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2483, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2483, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2483, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2499, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2499, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2499, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2499, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2499, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2508, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2508, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2508, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2508, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2508, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2943, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2943, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2943, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2943, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2943, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2505, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2505, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2505, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2505, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2505, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2979, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2979, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2979, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2979, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2979, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2789, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2789, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2789, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2789, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2789, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2680, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2680, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2680, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2680, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2680, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2959, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2959, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2959, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2959, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2959, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2576, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2576, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2576, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2576, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2576, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2508, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2508, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2508, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2508, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2508, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2472, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2472, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2472, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2472, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2472, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2731, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2731, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2731, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2731, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2731, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2082, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2082, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2082, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2082, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2082, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2943, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2943, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2943, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2943, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2943, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2579, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2579, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2579, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2579, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2579, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2648, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2648, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2648, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2648, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2648, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2726, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2726, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2726, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2726, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2726, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2318, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2318, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2318, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2318, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2318, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2636, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2636, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2636, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2636, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2636, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2384, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2384, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2384, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2384, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2384, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2179, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2179, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2179, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2179, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2179, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1978, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1978, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1978, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1978, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1978, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2344, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2344, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2344, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2344, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2344, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2586, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2586, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2586, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2586, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2586, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2162, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2162, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2162, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2162, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2162, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2932, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2932, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2932, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2932, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2932, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2051, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2051, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2051, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2051, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2051, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2319, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2319, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2319, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2319, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2319, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2724, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2724, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2724, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2724, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2724, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2374, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2374, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2374, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2374, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2374, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2630, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2630, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2630, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2630, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2630, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2400, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2400, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2400, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2400, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2400, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2292, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2292, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2292, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2292, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2292, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2286, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2286, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2286, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2286, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2286, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2458, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2458, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2458, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2458, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2458, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1311, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1311, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1311, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1311, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1311, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1586, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1586, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1586, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1586, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1586, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1892, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1892, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1892, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1892, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1892, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2354, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2354, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2354, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2354, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2354, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1956, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1956, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1956, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1956, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1956, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2335, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2335, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2335, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2335, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2335, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2005, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2005, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2005, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2005, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2005, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2571, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2571, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2571, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2571, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2571, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2361, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2361, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2361, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2361, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2361, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2556, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2556, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2556, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2556, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2556, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2788, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2788, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2788, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2788, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2788, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2390, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2390, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2390, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2390, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2390, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2440, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2440, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2440, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2440, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2440, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2189, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2189, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2189, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2189, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2189, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2080, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2080, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2080, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2080, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2080, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1753, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1753, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1753, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1753, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1753, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2953, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2953, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2953, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2953, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2953, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1651, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1651, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1651, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1651, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1651, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2107, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2107, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2107, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2107, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2107, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2518, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2518, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2518, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2518, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2518, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2320, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2320, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2320, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2320, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2320, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1806, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1806, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1806, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1806, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1806, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1763, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1763, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1763, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1763, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1763, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2753, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2753, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2753, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2753, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2753, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1875, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1875, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1875, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1875, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1875, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2136, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2136, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2136, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2136, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2136, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1886, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1886, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1886, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1886, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1886, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2133, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2133, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2133, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2133, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2133, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1748, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1748, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1748, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1748, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1748, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1855, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1855, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1855, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1855, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1855, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3067, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3067, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3067, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3067, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3067, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2598, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2598, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2598, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2598, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2598, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2075, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2075, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2075, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2075, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2075, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2739, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2739, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2739, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2739, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2739, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2181, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2181, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2181, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2181, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2181, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1858, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1858, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1858, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1858, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1858, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1633, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1633, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1633, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1633, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1633, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1913, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1913, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1913, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1913, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1913, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1502, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1502, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1502, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1502, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1502, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2581, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2581, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2581, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2581, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2581, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2705, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2705, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2705, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2705, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2705, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1872, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1872, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1872, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1872, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1872, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2208, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2208, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2208, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2208, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2208, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2180, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2180, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2180, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2180, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2180, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2418, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2418, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2418, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2418, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2418, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2267, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2267, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2267, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2267, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2267, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2021, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2021, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2021, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2021, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2021, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2346, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2346, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2346, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2346, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2346, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2874, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2874, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2874, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2874, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2874, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2397, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2397, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2397, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2397, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2397, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1772, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1772, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1772, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1772, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1772, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1812, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1812, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1812, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1812, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1812, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2225, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2225, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2225, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2225, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2225, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2107, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2107, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2107, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2107, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2107, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1629, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1629, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1629, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1629, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1629, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1961, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1961, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1961, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1961, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1961, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2232, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2232, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2232, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2232, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2232, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2107, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2107, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2107, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2107, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2107, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0817, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0817, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0817, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0817, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0817, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2075, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2075, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2075, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2075, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2075, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1506, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1506, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1506, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1506, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1506, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2323, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2323, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2323, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2323, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2323, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1910, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1910, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1910, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1910, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1910, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1545, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1545, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1545, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1545, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1545, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1094, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1094, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1094, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1094, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1094, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1947, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1947, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1947, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1947, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1947, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1789, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1789, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1789, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1789, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1789, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2052, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2052, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2052, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2052, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2052, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1783, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1783, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1783, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1783, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1783, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2054, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2054, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2054, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2054, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2054, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1918, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1918, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1918, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1918, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1918, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1288, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1288, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1288, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1288, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1288, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2372, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2372, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2372, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2372, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2372, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1138, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1138, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1138, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1138, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1138, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1093, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1093, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1093, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1093, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1093, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1329, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1329, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1329, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1329, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1329, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2045, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2045, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2045, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2045, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2045, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1721, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1721, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1721, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1721, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1721, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1950, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1950, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1950, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1950, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1950, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1907, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1907, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1907, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1907, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1907, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1555, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1555, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1555, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1555, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1555, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1731, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1731, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1731, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1731, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1731, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1669, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1669, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1669, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1669, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1669, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2201, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2201, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2201, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2201, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2201, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2004, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2004, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2004, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2004, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2004, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2019, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2019, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2019, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2019, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2019, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1776, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1776, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1776, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1776, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1776, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2114, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2114, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2114, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2114, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2114, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0644, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0644, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0644, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0644, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0644, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2100, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2100, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2100, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2100, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2100, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2143, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2143, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2143, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2143, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2143, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1254, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1254, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1254, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1254, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1254, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1008, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1008, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1008, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1008, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1008, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1399, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1399, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1399, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1399, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1399, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1557, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1557, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1557, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1557, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1557, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1586, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1586, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1586, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1586, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1586, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1481, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1481, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1481, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1481, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1481, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1742, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1742, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1742, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1742, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1742, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1147, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1147, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1147, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1147, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1147, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2170, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2170, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2170, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2170, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2170, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1801, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1801, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1801, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1801, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1801, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2310, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2310, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2310, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2310, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2310, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2037, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2037, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2037, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2037, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2037, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1666, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1666, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1666, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1666, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1666, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1736, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1736, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1736, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1736, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1736, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1922, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1922, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1922, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1922, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1922, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1875, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1875, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1875, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1875, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1875, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2459, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2459, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2459, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2459, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2459, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2173, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2173, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2173, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2173, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2173, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0924, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0924, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0924, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0924, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0924, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1280, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1280, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1280, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1280, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1280, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1782, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1782, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1782, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1782, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1782, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2214, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2214, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2214, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2214, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2214, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1517, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1517, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1517, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1517, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1517, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0919, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0919, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0919, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0919, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0919, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1417, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1417, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1417, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1417, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1417, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1906, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1906, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1906, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1906, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1906, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1920, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1920, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1920, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1920, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1920, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2214, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2214, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2214, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2214, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2214, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2364, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2364, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2364, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2364, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2364, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1714, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1714, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1714, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1714, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1714, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2110, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2110, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2110, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2110, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2110, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2073, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2073, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2073, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2073, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2073, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2086, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2086, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2086, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2086, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2086, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2053, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2053, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2053, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2053, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2053, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1240, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1240, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1240, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1240, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1240, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1049, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1049, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1049, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1049, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1049, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2170, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2170, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2170, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2170, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2170, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1760, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1760, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1760, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1760, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1760, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0634, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0634, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0634, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0634, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0634, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2034, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2034, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2034, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2034, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2034, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1433, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1433, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1433, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1433, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1433, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2243, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2243, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2243, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2243, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2243, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1804, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1804, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1804, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1804, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1804, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0276, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0276, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0276, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0276, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0276, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0989, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0989, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0989, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0989, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0989, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1150, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1150, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1150, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1150, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1150, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2208, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2208, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2208, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2208, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2208, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0689, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0689, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0689, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0689, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0689, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1345, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1345, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1345, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1345, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1345, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1948, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1948, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1948, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1948, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1948, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1522, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1522, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1522, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1522, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1522, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1181, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1181, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1181, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1181, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1181, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1550, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1550, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1550, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1550, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1550, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1024, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1024, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1024, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1024, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1024, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0983, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0983, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0983, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0983, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0983, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0646, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0646, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0646, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0646, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0646, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1302, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1302, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1302, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1302, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1302, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1609, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1609, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1609, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1609, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1609, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0947, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0947, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0947, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0947, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0947, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0391, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0391, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0391, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0391, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0391, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2132, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2132, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2132, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2132, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2132, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0832, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0832, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0832, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0832, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0832, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1604, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1604, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1604, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1604, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1604, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1726, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1726, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1726, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1726, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1726, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1134, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1134, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1134, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1134, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1134, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1615, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1615, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1615, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1615, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1615, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1625, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1625, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1625, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1625, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1625, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1881, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1881, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1881, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1881, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1881, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1751, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1751, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1751, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1751, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1751, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1063, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1063, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1063, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1063, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1063, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2008, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2008, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2008, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2008, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2008, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1402, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1402, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1402, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1402, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1402, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0679, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0679, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0679, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0679, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0679, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1025, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1025, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1025, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1025, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1025, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2608, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2608, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2608, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2608, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2608, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0353, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0353, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0353, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0353, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0353, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0841, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0841, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0841, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0841, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0841, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2297, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2297, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2297, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2297, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2297, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0366, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0366, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0366, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0366, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0366, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0401, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0401, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0401, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0401, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0401, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1478, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1478, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1478, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1478, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1478, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1655, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1655, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1655, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1655, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1655, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1554, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1554, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1554, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1554, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1554, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0679, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0679, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0679, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0679, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0679, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1981, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1981, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1981, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1981, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1981, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0684, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0684, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0684, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0684, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0684, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0936, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0936, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0936, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0936, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0936, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2374, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2374, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2374, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2374, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2374, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1725, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1725, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1725, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1725, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1725, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1052, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1052, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1052, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1052, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1052, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2008, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2008, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2008, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2008, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2008, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1507, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1507, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1507, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1507, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1507, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1479, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1479, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1479, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1479, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1479, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1937, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1937, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1937, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1937, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1937, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1681, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1681, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1681, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1681, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1681, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1259, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1259, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1259, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1259, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1259, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1054, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1054, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1054, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1054, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1054, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1086, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1086, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1086, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1086, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1086, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1135, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1135, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1135, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1135, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1135, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1395, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1395, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1395, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1395, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1395, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1375, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1375, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1375, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1375, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1375, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1730, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1730, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1730, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1730, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1730, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1842, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1842, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1842, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1842, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1842, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1667, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1667, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1667, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1667, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1667, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2042, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2042, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2042, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2042, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2042, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0838, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0838, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0838, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0838, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0838, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1662, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1662, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1662, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1662, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1662, device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "\n",
    "#setup trial\n",
    "params = parameter_dictionary\n",
    "trial_estimators = params['estimator_n']\n",
    "epoch_results = []\n",
    "epoch_ens_train_losses = []\n",
    "epoch_ens_test_losses = []\n",
    "epoch_member_train_losses = []\n",
    "epoch_member_test_losses = []\n",
    "\n",
    "trial_x, trial_y = train_data, train_labels\n",
    "trial_dset = minimal_implementation_dataset(trial_x, trial_y, params['device'])\n",
    "trial_dloader = torch.utils.data.DataLoader(trial_dset, batch_size = params['batch_size'], shuffle=True, generator=torch_generator)\n",
    "trial_unshuffled_dloader = torch.utils.data.DataLoader(trial_dset, batch_size = len(trial_dset), shuffle=False)\n",
    "\n",
    "trial_criterion = params['criterion']\n",
    "# init model\n",
    "ensemble = []\n",
    "optims = []\n",
    "losses = []\n",
    "\n",
    "\n",
    "for member_n in range(trial_estimators):\n",
    "    ensemble.append(ImageWOOF_SimpleConvnet(torch_generator).to(params['device']))\n",
    "    optims.append(torch.optim.Adam(ensemble[member_n].parameters()))\n",
    "    losses.append(None)\n",
    "    \n",
    "ens_runner = Ensemble_Runner(ensemble[0], params['combiner_rule'])\n",
    "lambda_ = 0\n",
    "\n",
    "overall_trial_stepcount = 0\n",
    "\n",
    "\n",
    "#run training\n",
    "for epoch in range(params['epoch_n']):\n",
    "    \n",
    "    trial_results_array = np.zeros((trial_estimators, len(test_data), imagewoof_classes))\n",
    "\n",
    "    for batch_idx, (batch_x, batch_y) in enumerate(trial_dloader):\n",
    "\n",
    "        batch_y = torch.as_tensor(batch_y, dtype=torch.long)\n",
    "        # get detached ensemble output\n",
    "\n",
    "        # if overall_trial_stepcount % consider_epoch_every_x_steps == 0:\n",
    "        \n",
    "        #     # print(overall_trial_stepcount, batch_idx)\n",
    "        #     member_test_losses = np.zeros((trial_estimators))\n",
    "        #     member_train_losses = np.zeros((trial_estimators))\n",
    "        #     with torch.no_grad():\n",
    "        #         trial_x_to_runnable = torch.tensor(trial_x).type(torch.float).to(params['device'])\n",
    "        #         trial_y_to_runnable = torch.tensor(trial_y).unsqueeze(dim=-1).type(torch.float).to(params['device'])\n",
    "        #         test_x_to_runnable = torch.tensor(test_data).type(torch.float).to(params['device'])\n",
    "        #         test_y_to_ens_runnable = torch.tensor(test_labels).unsqueeze(dim=-1).type(torch.float).to(params['device'])\n",
    "        #         trial_ensemble_output, trial_member_output = ens_runner.forward(trial_x_to_runnable, ensemble)\n",
    "        #         test_ensemble_output, test_member_output = ens_runner.forward(test_x_to_runnable, ensemble)\n",
    "        #         epoch_ens_train_losses.append(trial_criterion(trial_ensemble_output, trial_y_to_runnable).cpu())\n",
    "        #         epoch_ens_test_losses.append(trial_criterion(test_ensemble_output, test_y_to_ens_runnable).cpu())\n",
    "        #         trial_results_array = np.array(test_member_output.cpu().squeeze())\n",
    "        #         for i in range(trial_estimators):\n",
    "        #             # print(test_y_to_ens_runnable.size())\n",
    "        #             member_test_losses[i] = trial_criterion(test_member_output[i], test_y_to_ens_runnable).cpu()\n",
    "        #             member_train_losses[i] = trial_criterion(trial_member_output[i], trial_y_to_runnable).cpu()\n",
    "\n",
    "        #     epoch_results.append(np.array(trial_results_array))\n",
    "        #     epoch_member_train_losses.append(np.sort(member_train_losses))\n",
    "        #     epoch_member_test_losses.append(np.sort(member_test_losses))\n",
    "        #     overall_trial_stepcount += 1\n",
    "        \n",
    "        \n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, member_output = ens_runner.forward(batch_x, ensemble)\n",
    "        \n",
    "        # update each member\n",
    "        for i, member in enumerate(ensemble):\n",
    "            optims[i].zero_grad()\n",
    "            member_pred = member(batch_x)\n",
    "            member_grad_output = torch.cat((member_output[:i], member_pred.unsqueeze(dim=0), member_output[i+1:]))\n",
    "            ens_grad_output = params['combiner_rule'](member_grad_output)\n",
    "            # print(member_pred.dtype, batch_y.dtype, ens_grad_output.dtype)\n",
    "            losses[i] = ((trial_criterion(member_pred, batch_y)) - ((lambda_) * trial_criterion(member_pred, ens_grad_output)))\n",
    "            losses[i].backward()\n",
    "            optims[i].step()\n",
    "            print(losses[0])\n",
    "        \n",
    "        \n",
    "        # epoch_results.append(np.array(trial_results_array))\n",
    "        # epoch_member_train_losses.append(member_train_losses)\n",
    "        # epoch_member_test_losses.append(member_test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2021, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for member_n in range(trial_estimators):\n",
    "    ensemble.append(ImageWOOF_SimpleConvnet(torch_generator).to(params['device']))\n",
    "    optims.append(torch.optim.Adam(ensemble[member_n].parameters()))\n",
    "    losses.append(None)\n",
    "    \n",
    "ens_runner = Ensemble_Runner(ensemble[0], params['combiner_rule'])\n",
    "lambda_ = 0\n",
    "\n",
    "overall_trial_stepcount = 0\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for idx, (x, y) in enumerate(test_loader):\n",
    "    with torch.no_grad():\n",
    "        member_outs = []\n",
    "        for member in ensemble:\n",
    "            member_outs.append(member(x))\n",
    "        ens_out = params['combiner_rule'](torch.cat(member_outs, dim=0))\n",
    "        correct += torch.sum(torch.argmax(torch.nn.functional.softmax(ens_out, dim=-1), -1) == y)\n",
    "        total += len(y)\n",
    "print(correct / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[409 408 418 224 401 407 401 422 429 410]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 121\u001b[0m\n\u001b[1;32m    117\u001b[0m results_objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(total_step_count_estimate \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m-\u001b[39mconsider_epoch_every_x_steps)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# ceiling divison plus 0 step result object\u001b[39;00m\n\u001b[1;32m    118\u001b[0m study \u001b[38;5;241m=\u001b[39m bvdlib\u001b[38;5;241m.\u001b[39mNCL_Study(trial_space, parameter_dictionary, train_data, train_labels, test_data, test_labels, \n\u001b[1;32m    119\u001b[0m                     num_training, n_trials, decomp_fn, num_results_objects\u001b[38;5;241m=\u001b[39mresults_objs, estimator_n\u001b[38;5;241m=\u001b[39mparameter_dictionary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mestimator_n\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 121\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_run\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(save_path_without_extension):\n\u001b[1;32m    124\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(save_path_without_extension)\n",
      "File \u001b[0;32m~/work/EDMP/diversity-enforced-ensembles/experiments/../src/bvdlib/ncl_study.py:146\u001b[0m, in \u001b[0;36mNCL_Study.run_trials\u001b[0;34m(self, trial_function)\u001b[0m\n\u001b[1;32m    142\u001b[0m trial \u001b[38;5;241m=\u001b[39m Trial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data[trial_idx], \n\u001b[1;32m    143\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_labels[trial_idx],\n\u001b[1;32m    144\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_dict)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m#run trial\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m trial_results, train_losses, indiv_train_losses, indiv_test_losses, test_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrial_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_results_objects):\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# update the average loss after a trial\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     total_train_loss_epoch[result_num] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_trials) \u001b[38;5;241m*\u001b[39m train_losses[result_num]\n",
      "Cell \u001b[0;32mIn[13], line 57\u001b[0m, in \u001b[0;36mtrial_run\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     55\u001b[0m test_x_to_runnable \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(test_data)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mto(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     56\u001b[0m test_y_to_ens_runnable \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(test_labels)\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mto(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 57\u001b[0m trial_ensemble_output, trial_member_output \u001b[38;5;241m=\u001b[39m \u001b[43mens_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_x_to_runnable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensemble\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m test_ensemble_output, test_member_output \u001b[38;5;241m=\u001b[39m ens_runner\u001b[38;5;241m.\u001b[39mforward(test_x_to_runnable, ensemble)\n\u001b[1;32m     59\u001b[0m epoch_ens_train_losses\u001b[38;5;241m.\u001b[39mappend(trial_criterion(trial_ensemble_output, trial_y_to_runnable)\u001b[38;5;241m.\u001b[39mcpu())\n",
      "File \u001b[0;32m~/work/EDMP/diversity-enforced-ensembles/experiments/../src/ml_utils/ensemble_utils.py:53\u001b[0m, in \u001b[0;36mEnsemble_Runner.forward\u001b[0;34m(self, x, ensemble)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, ensemble):\n\u001b[1;32m     51\u001b[0m     params, buffers \u001b[38;5;241m=\u001b[39m stack_module_state(nn\u001b[38;5;241m.\u001b[39mModuleList(ensemble))\n\u001b[0;32m---> 53\u001b[0m     member_output \u001b[38;5;241m=\u001b[39m vmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_through_metamodel)(params, buffers, \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mensemble\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# print(member_output.shape)\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     ensemble_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombiner_rule(member_output)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor"
     ]
    }
   ],
   "source": [
    "# define a trial\n",
    "def trial_run(trial):\n",
    "  \n",
    "\n",
    "  #setup trial\n",
    "  params = trial.get_params\n",
    "  trial_estimators = params['estimator_n']\n",
    "  epoch_results = []\n",
    "  epoch_ens_train_losses = []\n",
    "  epoch_ens_test_losses = []\n",
    "  epoch_member_train_losses = []\n",
    "  epoch_member_test_losses = []\n",
    "\n",
    "  trial_x, trial_y = trial.get_data\n",
    "  trial_dset = minimal_implementation_dataset(trial_x, trial_y, params['device'])\n",
    "  trial_dloader = torch.utils.data.DataLoader(trial_dset, batch_size = params['batch_size'], shuffle=True, generator=torch_generator)\n",
    "  # trial_unshuffled_dloader = torch.utils.data.DataLoader(trial_dset, batch_size = len(trial_dset), shuffle=False)\n",
    "\n",
    "  trial_criterion = params['criterion']\n",
    "  # init model\n",
    "  ensemble = []\n",
    "  optims = []\n",
    "  losses = []\n",
    "\n",
    "  \n",
    "  for member_n in range(trial_estimators):\n",
    "      ensemble.append(ImageWOOF_SimpleConvnet(torch_generator).to(params['device']))\n",
    "      optims.append(torch.optim.Adam(ensemble[member_n].parameters()))\n",
    "      losses.append(None)\n",
    "      \n",
    "  ens_runner = Ensemble_Runner(ensemble[0], params['combiner_rule'])\n",
    "  lambda_ = params['lambda']\n",
    "\n",
    "  overall_trial_stepcount = 0\n",
    "\n",
    "\n",
    "  #run training\n",
    "  for epoch in range(params['epoch_n']):\n",
    "     \n",
    "    trial_results_array = np.zeros((trial_estimators, len(test_data), imagewoof_classes))\n",
    "\n",
    "    for batch_idx, (batch_x, batch_y) in enumerate(trial_dloader):\n",
    "      # get detached ensemble output\n",
    "\n",
    "      if overall_trial_stepcount % consider_epoch_every_x_steps == 0:\n",
    "        \n",
    "        # print(overall_trial_stepcount, batch_idx)\n",
    "        member_test_losses = np.zeros((trial_estimators))\n",
    "        member_train_losses = np.zeros((trial_estimators))\n",
    "        with torch.no_grad():\n",
    "            trial_x_to_runnable = torch.tensor(trial_x).type(torch.float).to(params['device'])\n",
    "            trial_y_to_runnable = torch.tensor(trial_y).unsqueeze(dim=-1).type(torch.float).to(params['device'])\n",
    "            test_x_to_runnable = torch.tensor(test_data).type(torch.float).to(params['device'])\n",
    "            test_y_to_ens_runnable = torch.tensor(test_labels).unsqueeze(dim=-1).type(torch.float).to(params['device'])\n",
    "            trial_ensemble_output, trial_member_output = ens_runner.forward(trial_x_to_runnable, ensemble)\n",
    "            test_ensemble_output, test_member_output = ens_runner.forward(test_x_to_runnable, ensemble)\n",
    "            epoch_ens_train_losses.append(trial_criterion(trial_ensemble_output, trial_y_to_runnable).cpu())\n",
    "            epoch_ens_test_losses.append(trial_criterion(test_ensemble_output, test_y_to_ens_runnable).cpu())\n",
    "            trial_results_array = np.array(test_member_output.cpu().squeeze())\n",
    "            for i in range(trial_estimators):\n",
    "              # print(test_y_to_ens_runnable.size())\n",
    "              member_test_losses[i] = trial_criterion(test_member_output[i], test_y_to_ens_runnable).cpu()\n",
    "              member_train_losses[i] = trial_criterion(trial_member_output[i], trial_y_to_runnable).cpu()\n",
    "\n",
    "        epoch_results.append(np.array(trial_results_array))\n",
    "        epoch_member_train_losses.append(np.sort(member_train_losses))\n",
    "        epoch_member_test_losses.append(np.sort(member_test_losses))\n",
    "      overall_trial_stepcount += 1\n",
    "        \n",
    "        \n",
    "\n",
    "      with torch.no_grad():\n",
    "        _, member_output = ens_runner.forward(batch_x, ensemble)\n",
    "        \n",
    "      # update each member\n",
    "      for i, member in enumerate(ensemble):\n",
    "        optims[i].zero_grad()\n",
    "        member_pred = member(batch_x)\n",
    "        member_grad_output = torch.cat((member_output[:i], member_pred.unsqueeze(dim=0), member_output[i+1:]))\n",
    "        ens_grad_output = params['combiner_rule'](member_grad_output)\n",
    "        losses[i] = ((0.5* trial_criterion(member_pred, batch_y.unsqueeze(dim=-1))) - ((lambda_) * trial_criterion(member_pred, ens_grad_output)))\n",
    "        losses[i].backward()\n",
    "        optims[i].step()\n",
    "      # print(member_loss)\n",
    "        \n",
    "        \n",
    "      epoch_results.append(np.array(trial_results_array))\n",
    "      epoch_member_train_losses.append(member_train_losses)\n",
    "      epoch_member_test_losses.append(member_test_losses)\n",
    "  \n",
    "  return epoch_results, epoch_ens_train_losses, epoch_member_train_losses, epoch_member_test_losses, epoch_ens_test_losses\n",
    "\n",
    "# save results\n",
    "  \n",
    "total_step_count_estimate = (parameter_dictionary['epoch_n'] * (num_training // parameter_dictionary['batch_size']))\n",
    "results_objs = -(total_step_count_estimate // -consider_epoch_every_x_steps)+1 # ceiling divison plus 0 step result object\n",
    "study = bvdlib.NCL_Study(trial_space, parameter_dictionary, train_data, train_labels, test_data, test_labels, \n",
    "                    num_training, n_trials, decomp_fn, num_results_objects=results_objs, estimator_n=parameter_dictionary['estimator_n'])\n",
    "\n",
    "results = study.run_trials(trial_run)\n",
    "\n",
    "if not os.path.exists(save_path_without_extension):\n",
    "    os.makedirs(save_path_without_extension)\n",
    "\n",
    "for epoch, result in enumerate(results):\n",
    "  this_save_path = save_path_without_extension + \"/stepmeasure_\" + str(epoch) + \".pkl\"\n",
    "  result.save_results(this_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='lambda'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from decompose.plotting_utils import plot_bvd\n",
    "print(len(results))\n",
    "results_idx = 25\n",
    "\n",
    "ax = plot_bvd(results[results_idx])\n",
    "# print(results[results_idx].diversity)\n",
    "# print(results[results_idx].average_variance)\n",
    "# ax.set_xlim(0,0.4)results[results_idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensemble-diversity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
