{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # local\n",
    "project_directory = \"../\"\n",
    "\n",
    "\n",
    "# # # # colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# project_directory = \"/content/drive/MyDrive/colab_working_directory/diversity-enforced-ensembles/\"\n",
    "# !pip install cached-property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# allow import of decompose locally\n",
    "import sys\n",
    "sys.path.append(project_directory + 'src/')\n",
    "\n",
    "from decompose import SquaredLoss\n",
    "import bvdlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.func import stack_module_state\n",
    "from torch.func import functional_call\n",
    "from torch import vmap\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer(layer, generator):\n",
    "    torch.nn.init.xavier_uniform_(layer.weight, generator=generator)\n",
    "    layer.bias.data.fill_(0.01)\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, generator):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        init_layer(self.fc1, generator)\n",
    "\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        init_layer(self.fc2, generator)\n",
    "\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        init_layer(self.fc3, generator)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_through_metamodel(params, buffers, x):\n",
    "        return functional_call(meta_model, (params, buffers), (x,))\n",
    "\n",
    "def torch_MSE_combiner(ensemble_output):\n",
    "    return torch.mean(ensemble_output, axis=0)\n",
    "\n",
    "combiner_rule = torch_MSE_combiner\n",
    "\n",
    "def ens_forward(input, ensemble):\n",
    "\n",
    "  params, buffers = stack_module_state(nn.ModuleList(ensemble))\n",
    "\n",
    "  member_output = vmap(forward_through_metamodel)(params, buffers, input.repeat(len(ensemble), 1, 1))\n",
    "\n",
    "  ensemble_output = combiner_rule(member_output)\n",
    "  return ensemble_output, member_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_space = np.arange(0,15) / 10\n",
    "decomp_fn = SquaredLoss\n",
    "seed = 0\n",
    "criterion = torch.nn.MSELoss()\n",
    "epoch_n=7\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "torch_generator = torch.manual_seed(0)\n",
    "\n",
    "x = torch.rand((200,13), dtype=torch.float).to(device)\n",
    "y = torch.randint(0,10,(200,),dtype=torch.float).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 11\n",
    "# init model\n",
    "ensemble = []\n",
    "optims = []\n",
    "losses = []\n",
    "for member_n in range(n_estimators):\n",
    "    ensemble.append(SimpleMLP(len(x[0]), 8, 1, torch_generator).to(device))\n",
    "    optims.append(torch.optim.SGD(ensemble[member_n].parameters(), lr=0.0001))\n",
    "    losses.append(None)\n",
    "\n",
    "meta_model = copy.deepcopy(ensemble[0]).to('meta')\n",
    "\n",
    "lambda_ = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook(grad):\n",
    "    print(\"grad[0]\", grad[0])\n",
    "    # print(grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW MEMBER\n",
      "y[0] tensor(8., device='cuda:0')\n",
      "mp[0] tensor([-0.5175], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "bad grad tensor([-8.0412], device='cuda:0')\n",
      "good grad tensor([-8.2577], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Ultra_bad_grad tensor([-17.0351], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(32.3215, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "grad[0] tensor([-0.0852], device='cuda:0')\n",
      "NEW MEMBER\n",
      "y[0] tensor(8., device='cuda:0')\n",
      "mp[0] tensor([0.1552], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "bad grad tensor([-8.0412], device='cuda:0')\n",
      "good grad tensor([-7.9519], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Ultra_bad_grad tensor([-15.6897], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.8612, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "grad[0] tensor([-0.0784], device='cuda:0')\n",
      "NEW MEMBER\n",
      "y[0] tensor(8., device='cuda:0')\n",
      "mp[0] tensor([0.1370], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "bad grad tensor([-8.0412], device='cuda:0')\n",
      "good grad tensor([-7.9602], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Ultra_bad_grad tensor([-15.7260], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.7810, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "grad[0] tensor([-0.0786], device='cuda:0')\n",
      "NEW MEMBER\n",
      "y[0] tensor(8., device='cuda:0')\n",
      "mp[0] tensor([-0.0029], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "bad grad tensor([-8.0412], device='cuda:0')\n",
      "good grad tensor([-8.0238], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Ultra_bad_grad tensor([-16.0059], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(29.5142, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "grad[0] tensor([-0.0800], device='cuda:0')\n",
      "NEW MEMBER\n",
      "y[0] tensor(8., device='cuda:0')\n",
      "mp[0] tensor([-0.1667], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "bad grad tensor([-8.0412], device='cuda:0')\n",
      "good grad tensor([-8.0982], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Ultra_bad_grad tensor([-16.3334], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(30.4844, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "grad[0] tensor([-0.0817], device='cuda:0')\n",
      "NEW MEMBER\n",
      "y[0] tensor(8., device='cuda:0')\n",
      "mp[0] tensor([0.0069], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "bad grad tensor([-8.0412], device='cuda:0')\n",
      "good grad tensor([-8.0193], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Ultra_bad_grad tensor([-15.9862], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.0731, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "grad[0] tensor([-0.0799], device='cuda:0')\n",
      "NEW MEMBER\n",
      "y[0] tensor(8., device='cuda:0')\n",
      "mp[0] tensor([0.0472], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "bad grad tensor([-8.0412], device='cuda:0')\n",
      "good grad tensor([-8.0010], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Ultra_bad_grad tensor([-15.9056], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(26.0980, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "grad[0] tensor([-0.0795], device='cuda:0')\n",
      "NEW MEMBER\n",
      "y[0] tensor(8., device='cuda:0')\n",
      "mp[0] tensor([-0.3944], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "bad grad tensor([-8.0412], device='cuda:0')\n",
      "good grad tensor([-8.2018], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Ultra_bad_grad tensor([-16.7889], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(31.2181, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "grad[0] tensor([-0.0839], device='cuda:0')\n",
      "NEW MEMBER\n",
      "y[0] tensor(8., device='cuda:0')\n",
      "mp[0] tensor([0.2504], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "bad grad tensor([-8.0412], device='cuda:0')\n",
      "good grad tensor([-7.9086], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Ultra_bad_grad tensor([-15.4992], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(25.8852, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "grad[0] tensor([-0.0775], device='cuda:0')\n",
      "NEW MEMBER\n",
      "y[0] tensor(8., device='cuda:0')\n",
      "mp[0] tensor([0.0578], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "bad grad tensor([-8.0412], device='cuda:0')\n",
      "good grad tensor([-7.9962], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Ultra_bad_grad tensor([-15.8844], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(27.5340, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "grad[0] tensor([-0.0794], device='cuda:0')\n",
      "NEW MEMBER\n",
      "y[0] tensor(8., device='cuda:0')\n",
      "mp[0] tensor([-0.0260], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "bad grad tensor([-8.0412], device='cuda:0')\n",
      "good grad tensor([-8.0343], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "Ultra_bad_grad tensor([-16.0520], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(29.5025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "grad[0] tensor([-0.0803], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "bx, by = x, y\n",
    "\n",
    "with torch.no_grad():\n",
    "    ensemble_output, member_output = ens_forward(bx, ensemble)\n",
    "\n",
    "member_output = member_output.detach()\n",
    "\n",
    "for i, member in enumerate(ensemble):\n",
    "    print(\"NEW MEMBER\")\n",
    "    optims[i].zero_grad()\n",
    "    member_pred = member(bx) #predict\n",
    "    member_pred.register_hook(hook)\n",
    "    print(\"y[0]\", y[0])\n",
    "    print(\"mp[0]\", member_pred[0])\n",
    "    print(\"bad grad\", ensemble_output[0] - y[0])\n",
    "    print(\"good grad\", (member_pred[0] - y[0] - (lambda_ * (2*(10/11)*(member_pred[0]-ensemble_output[0])))))\n",
    "    print(\"Ultra_bad_grad\", (2*(member_pred[0] - y[0])))\n",
    "    member_grad_output = ((1/n_estimators) * member_pred.unsqueeze(dim=0)) + (((1-n_estimators)/n_estimators)*torch.cat((member_output[:i], member_output[i+1:])).detach())\n",
    "    ens_grad_output = combiner_rule(member_grad_output)\n",
    "\n",
    "    # member_loss = (criterion(member_pred, by.unsqueeze(dim=-1)) + ((lambda_) * criterion(member_pred, ens_grad_output)))\n",
    "    member_loss = criterion(member_pred, by.unsqueeze(dim=-1))\n",
    "    # member_loss.register_hook(hook)\n",
    "    print(member_loss)\n",
    "    member_loss.backward()\n",
    "    optims[i].step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensemble-diversity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
